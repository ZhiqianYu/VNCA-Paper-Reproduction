{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ytXUYst1kbP","outputId":"cc48fc2a-6738-4c19-b10b-79417f8400e2","trusted":true},"outputs":[],"source":["!git clone https://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@github.com/albertaillet/vnca.git -b master"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%capture\n","%pip install --upgrade jax tensorflow_probability tensorflow jaxlib numpy equinox einops optax distrax wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","\n","if 'TPU_NAME' in os.environ:\n","    import requests\n","\n","    if 'TPU_DRIVER_MODE' not in globals():\n","        url = 'http:' + os.environ['TPU_NAME'].split(':')[1] + ':8475/requestversion/tpu_driver_nightly'\n","        resp = requests.post(url)\n","        TPU_DRIVER_MODE = 1\n","\n","    from jax.config import config\n","\n","    config.FLAGS.jax_xla_backend = \"tpu_driver\"\n","    config.FLAGS.jax_backend_target = os.environ['TPU_NAME']\n","    print('Registered TPU:', config.FLAGS.jax_backend_target)\n","else:\n","    print('No TPU detected. Can be changed under \"Runtime/Change runtime type\".')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YBGL-I4Q1bjW","outputId":"b48546a7-dc38-4729-bb6a-db74896dfbb8","trusted":true},"outputs":[],"source":["%cd /kaggle/working/vnca"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0bzOEnDU1bja","trusted":true},"outputs":[],"source":["# Imports\n","import time\n","import wandb\n","import equinox as eqx\n","import jax.numpy as np\n","from jax import debug\n","from jax.random import PRNGKey, split, permutation\n","from jax import vmap, pmap, local_device_count, lax, local_devices, device_put_replicated, device_put, tree_map, jit, nn\n","from einops import rearrange, repeat\n","from optax import adam, exponential_decay, clip_by_global_norm, chain\n","import matplotlib.pyplot as plt\n","from functools import partial\n","from tqdm import tqdm\n","from distrax import Normal, Bernoulli\n","from data import mnist\n","\n","from models import BaselineVAE\n","\n","# typing\n","from jax import Array\n","from equinox import Module\n","from typing import Optional, Any\n","from jax.random import PRNGKeyArray\n","from optax import GradientTransformation\n","from typing import Tuple\n","\n","TARGET_SIZE = 28\n","MODEL_KEY = PRNGKey(0)\n","DATA_KEY = PRNGKey(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ChAGUXJO1bjb","trusted":true},"outputs":[],"source":["@eqx.filter_value_and_grad\n","def loss_fn(model: Module, x: Array, key: PRNGKeyArray) -> float:\n","    keys = split(key, x.shape[0])\n","    recon_x, mean, logvar = vmap(model)(x, key=keys)\n","    kl_loss = np.sum(Normal(mean, np.exp(1 / 2 * logvar)).kl_divergence(Normal(0, 1)), axis=1)\n","    recon_loss = -np.sum(Bernoulli(logits=recon_x).log_prob(x), axis=(1, 2, 3))\n","    return np.mean(recon_loss + kl_loss)\n","\n","\n","@partial(pmap, axis_name='num_devices', static_broadcasted_argnums=(3, 6), out_axes=(None, 0, 0))\n","def make_step(data: Array, index: Array, params, static, key: PRNGKeyArray, opt_state: tuple, optim: GradientTransformation) -> Tuple[float, Module, Any]:\n","    def step(carry, index):\n","        params, opt_state, key = carry\n","        x = data[index]\n","        key, subkey = split(key)\n","\n","        model = eqx.combine(params, static)\n","        loss, grads = loss_fn(model, x, subkey)\n","        loss = lax.pmean(loss, axis_name='num_devices')\n","        grads = lax.pmean(grads, axis_name='num_devices')\n","\n","        updates, opt_state = optim.update(grads, opt_state)\n","        params = eqx.apply_updates(params, updates)\n","        return (params, opt_state, key), loss\n","\n","    (params, opt_state, key), loss = lax.scan(step, (params, opt_state, key), index)\n","    return loss, params, opt_state\n","\n","def save_model(model, step):\n","    model_file_name = f'{model.__class__.__name__}_gstep{step}.eqx'\n","    eqx.tree_serialise_leaves(model_file_name, model)\n","    wandb.save(model_file_name)\n","    \n","def restore_model(model_like, file_name, run_path=None):\n","    wandb.restore(file_name, run_path=run_path)\n","    model = eqx.tree_deserialise_leaves(file_name, model_like)\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CFiDHgp81bjb","trusted":true},"outputs":[],"source":["# Create model and define parameters\n","model = BaselineVAE(key=MODEL_KEY)\n","\n","n_tpus = local_device_count()\n","devices = local_devices()\n","data = mnist.load_mnist_train_on_tpu(devices=local_devices())\n","\n","n_tpus, devices"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["wandb.init(project=\"vnca\", entity=\"albertaillet\")\n","\n","wandb.config.model_type = model.__class__.__name__\n","wandb.config.batch_size = 32 // n_tpus\n","wandb.config.n_gradient_steps = 1000\n","wandb.config.n_tpus = n_tpus\n","wandb.config.lr = 4e-5\n","# wandb.config.lr_init_value = 3e-4 # when using exponential_decay\n","# wandb.config.lr_transition_steps = 100_000\n","# wandb.config.lr_decay_rate = 0.3\n","# wandb.config.lr_staircase = True\n","wandb.config.grad_norm_clip = 10.0\n","wandb.config.l = 500\n","wandb.config.model_key = MODEL_KEY\n","wandb.config.data_key = DATA_KEY\n","wandb.config.log_every = 1000"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kQ5UKEri1bjc","trusted":true},"outputs":[],"source":["train_keys = split(DATA_KEY, wandb.config.n_gradient_steps * n_tpus)\n","\n","train_keys = rearrange(train_keys, \"(n t) k -> n t k\", t=n_tpus, n=wandb.config.n_gradient_steps)\n","\n","params, static = eqx.partition(model, eqx.is_array)\n","\n","opt = chain(adam(wandb.config.lr), clip_by_global_norm(wandb.config.grad_norm_clip))\n","opt_state = opt.init(params)\n","\n","params = device_put_replicated(params, devices)\n","opt_state = device_put_replicated(opt_state, devices)\n","\n","pbar = tqdm(\n","    zip(\n","        range(wandb.config.n_gradient_steps),\n","        mnist.indicies_tpu_iterator(n_tpus, wandb.config.batch_size, data.shape[1], wandb.config.n_gradient_steps, DATA_KEY, wandb.config.l), \n","        train_keys\n","    ),\n","    total=wandb.config.n_gradient_steps,\n",")\n","\n","for i, idx, key in pbar:\n","    start_t = time.time()\n","    loss, params, opt_state = make_step(data, idx, params, static, key, opt_state, opt)\n","    pbar.set_postfix({'loss': f\"{np.mean(loss):.3}\"})\n","    \n","    wandb.log({\n","        'loss': float(np.mean(loss)),\n","        'avg_steps_per_s': i / (pbar.last_print_t - pbar.start_t),\n","        'step_time': time.time() - start_t,\n","    })\n","    \n","    n_gradient_steps = i * wandb.config.l\n","    if n_gradient_steps % wandb.config.log_every == 0:\n","        model = eqx.combine(tree_map(partial(np.mean, axis=0), params), static)\n","        save_model(model, n_gradient_steps)\n","\n","model = eqx.combine(tree_map(partial(np.mean, axis=0), params), static)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["local_data = mnist.get_mnist(split=['test'])['test']\n","\n","fig = local_data[201]\n","plt.imshow(nn.sigmoid(model(fig, key=DATA_KEY)[0][0]), cmap='gray')\n","plt.show()\n","plt.imshow(np.pad(fig[0], ((2, 2), (2, 2))), cmap='gray')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig = local_data[41010]\n","plt.imshow(nn.sigmoid(model(fig, key=DATA_KEY)[0][0]), cmap='gray')\n","plt.show()\n","plt.imshow(fig[0], cmap='gray')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"vscode":{"interpreter":{"hash":"9ff20ed1977ab5e52e5fa3818b5a3468a36e4698e9acfbcafb091a6dc7704046"}}},"nbformat":4,"nbformat_minor":4}
