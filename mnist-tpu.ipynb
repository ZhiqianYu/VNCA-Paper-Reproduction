{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ytXUYst1kbP","outputId":"cc48fc2a-6738-4c19-b10b-79417f8400e2","trusted":true},"outputs":[],"source":["!git clone https://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@github.com/albertaillet/vnca.git"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%capture\n","!pip install --upgrade jax tensorflow_probability tensorflow jaxlib numpy equinox einops optax distrax wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","\n","if 'TPU_NAME' in os.environ:\n","    import requests\n","\n","    if 'TPU_DRIVER_MODE' not in globals():\n","        url = 'http:' + os.environ['TPU_NAME'].split(':')[1] + ':8475/requestversion/tpu_driver_nightly'\n","        resp = requests.post(url)\n","        TPU_DRIVER_MODE = 1\n","\n","    from jax.config import config\n","\n","    config.FLAGS.jax_xla_backend = \"tpu_driver\"\n","    config.FLAGS.jax_backend_target = os.environ['TPU_NAME']\n","    print('Registered TPU:', config.FLAGS.jax_backend_target)\n","else:\n","    print('No TPU detected. Can be changed under \"Runtime/Change runtime type\".')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YBGL-I4Q1bjW","outputId":"b48546a7-dc38-4729-bb6a-db74896dfbb8","trusted":true},"outputs":[],"source":["%cd /kaggle/working/vnca"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0bzOEnDU1bja","trusted":true},"outputs":[],"source":["# Imports\n","import equinox as eqx\n","import jax.numpy as np\n","from jax import debug\n","from jax.random import PRNGKey, split, permutation\n","from jax import vmap, pmap, local_device_count, lax, local_devices, device_put_replicated, device_put, tree_map, devices, jit, nn\n","from einops import rearrange, repeat\n","from optax import adam, exponential_decay, clip_by_global_norm, chain\n","import matplotlib.pyplot as plt\n","from functools import partial\n","from tqdm import tqdm\n","from distrax import Normal, Bernoulli\n","from data.mnist import load_mnist_train_on_tpu, indicies_tpu_iterator, MNIST\n","\n","from models import BaselineVAE\n","\n","# typing\n","from jax import Array\n","from equinox import Module\n","from typing import Optional, Any\n","from jax.random import PRNGKeyArray\n","from optax import GradientTransformation\n","from typing import Tuple\n","\n","TARGET_SIZE = 28\n","MODEL_KEY = PRNGKey(0)\n","DATA_KEY = PRNGKey(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ChAGUXJO1bjb","trusted":true},"outputs":[],"source":["@eqx.filter_value_and_grad\n","def loss_fn(model: Module, x: Array, key: PRNGKeyArray) -> float:\n","    keys = split(key, x.shape[0])\n","    recon_x, mean, logvar = vmap(model)(x, keys)\n","    kl_loss = np.sum(Normal(mean, np.exp(1 / 2 * logvar)).kl_divergence(Normal(0, 1)), axis=1)\n","    recon_loss = -np.sum(Bernoulli(logits=recon_x).log_prob(x), axis=(1, 2, 3))\n","    return np.mean(recon_loss + kl_loss)\n","\n","\n","@partial(pmap, axis_name='num_devices', static_broadcasted_argnums=(3, 6), out_axes=(None, 0, 0))\n","def make_step(data: Array, index: Array, params, static, key: PRNGKeyArray, opt_state: tuple, optim: GradientTransformation) -> Tuple[float, Module, Any]:\n","    def step(carry, index):\n","        params, opt_state, key = carry\n","        x = data[index]\n","        key, subkey = split(key)\n","\n","        model = eqx.combine(params, static)\n","        loss, grads = loss_fn(model, x, subkey)\n","        loss = lax.pmean(loss, axis_name='num_devices')\n","        grads = lax.pmean(grads, axis_name='num_devices')\n","\n","        updates, opt_state = optim.update(grads, opt_state)\n","        params = eqx.apply_updates(params, updates)\n","        return (params, opt_state, key), loss\n","\n","    (params, opt_state, key), loss = lax.scan(step, (params, opt_state, key), index)\n","    return loss, params, opt_state"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CFiDHgp81bjb","trusted":true},"outputs":[],"source":["# Create model and define parameters\n","model = BaselineVAE(key=MODEL_KEY)\n","\n","data = load_mnist_train_on_tpu(devices=devices())\n","\n","n_tpus = local_device_count()\n","devices = local_devices()\n","n_tpus, devices"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import wandb\n","\n","wandb.init(project=\"vnca\", entity=\"albertaillet\")\n","\n","wandb.config.model_type = model.__class__.__name__\n","wandb.config.batch_size = 32 // n_tpus * 8 * 4\n","wandb.config.n_gradient_steps = 1000\n","wandb.config.n_tpus = n_tpus\n","wandb.config.lr = 4e-5\n","# wandb.config.lr_init_value = 3e-4 # when using exponential_decay\n","# wandb.config.lr_transition_steps = 100_000\n","# wandb.config.lr_decay_rate = 0.3\n","# wandb.config.lr_staircase = True\n","wandb.config.grad_norm_clip = 10.0\n","wandb.config.l = 1_000\n","wandb.config.model_key = MODEL_KEY\n","wandb.config.data_key = DATA_KEY"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kQ5UKEri1bjc","trusted":true},"outputs":[],"source":["train_keys = split(DATA_KEY, wandb.config.n_gradient_steps * n_tpus)\n","\n","train_keys = rearrange(train_keys, \"(n t) k -> n t k\", t=n_tpus, n=wandb.config.n_gradient_steps)\n","\n","params, static = eqx.partition(model, eqx.is_array)\n","\n","opt = chain(adam(wandb.config.lr), clip_by_global_norm(wandb.config.grad_norm_clip))\n","opt_state = opt.init(params)\n","\n","params = device_put_replicated(params, devices)\n","opt_state = device_put_replicated(opt_state, devices)\n","\n","pbar = tqdm(\n","    zip(indicies_tpu_iterator(n_tpus, wandb.config.batch_size, data.shape[1], wandb.config.n_gradient_steps, DATA_KEY, wandb.config.l), train_keys),\n","    total=wandb.config.n_gradient_steps,\n",")\n","\n","for i, key in pbar:\n","    loss, params, opt_state = make_step(data, i, params, static, key, opt_state, opt)\n","    pbar.set_postfix({'loss': f\"{np.mean(loss):.3}\"})\n","    wandb.log({'loss': float(np.mean(loss))})\n","\n","model = eqx.combine(tree_map(partial(np.mean, axis=0), params), static)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig = data[0][201]\n","plt.imshow(nn.sigmoid(model(fig, DATA_KEY)[0][0]), cmap='gray')\n","plt.show()\n","fig = np.pad(fig, ((0, 0), (2, 2), (2, 2)))\n","plt.imshow(fig[0], cmap='gray')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_dataset = MNIST(root='./data', train=False, download=True, transform=None)\n","test_dataset = np.array(np.float32(test_dataset.data / 255.0))\n","test_dataset = rearrange(test_dataset, 'n h w -> n 1 h w')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig = test_dataset[400]\n","plt.imshow(nn.sigmoid(model(fig, DATA_KEY)[0][0]), cmap='gray')\n","plt.show()\n","plt.imshow(fig[0], cmap='gray')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"9ff20ed1977ab5e52e5fa3818b5a3468a36e4698e9acfbcafb091a6dc7704046"}}},"nbformat":4,"nbformat_minor":4}
